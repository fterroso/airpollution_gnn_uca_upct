{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d1029-e8e0-4e56-b1f0-547c218a1a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from airpollution_trf_graph_loader import AirpollutionDatasetLoader\n",
    "\n",
    "pd.options.display.float_format = '{:,.3f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d75af-a614-44d0-a9cc-15db36c8c3c7",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd4ab1-ef74-4920-8f3a-7ae3c2988535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_fn(actual, pred):\n",
    "    #print(actual)\n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / (actual+0.01))) * 100\n",
    "\n",
    "def compute_metrics_as_dataframe_fn(y_valid, y_hat, particle_name):\n",
    "    metrics= []\n",
    "    metrics_global = {'mse':[],'rmse':[],'mae':[],'cvrmse':[],'mape':[],}\n",
    "\n",
    "    try:\n",
    "        mae = mean_absolute_error(y_valid, y_hat)\n",
    "        mse = mean_squared_error(y_valid, y_hat)\n",
    "        rmse= mean_squared_error(y_valid, y_hat, squared = False)\n",
    "        cvrmse =  (rmse/np.mean(y_valid))*100 # it is a percentage\n",
    "        mape = mape_fn(y_valid, y_hat)\n",
    "\n",
    "        metrics.append((time_horizon, str(particle_name), mae, mse, rmse, cvrmse, mape))\n",
    "\n",
    "\n",
    "        metrics_df = pd.DataFrame.from_records(metrics, columns='T particle MAE MSE RMSE CVRMSE MAPE'.split())\n",
    "\n",
    "        return metrics_df\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def compute_metrics(y_valid, y_hat):\n",
    "    metrics= []\n",
    "    metrics_global = {'mse':[],'rmse':[],'mae':[],'cvrmse':[],'mape':[],}\n",
    "\n",
    "    mae = mean_absolute_error(y_valid, y_hat)\n",
    "    mse = mean_squared_error(y_valid, y_hat)\n",
    "    rmse= mean_squared_error(y_valid, y_hat, squared = False)\n",
    "    cvrmse =  (rmse/np.mean(y_valid))*100 # it is a percentage\n",
    "    mape = mape_fn(y_valid, y_hat)\n",
    "\n",
    "    return mae, mse, rmse, cvrmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686314b-f16d-4151-b9d7-9fca435619e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_lst= [6, 12,24,48] #target time horizons to analyze\n",
    "city_lst= 'madrid bilbao'.split()\n",
    "_include_trf= True # include or not traffic data as input\n",
    "\n",
    "results_path='results'\n",
    "\n",
    "for _city in city_lst:\n",
    "    print(\"\\n\")\n",
    "    print(\"*\"*24)\n",
    "\n",
    "    print(_city)\n",
    "    loader= AirpollutionDatasetLoader(_city, _include_trf)\n",
    "    dataset=loader.get_dataset(T=T_lst[0])\n",
    "\n",
    "    feature_dim= loader.get_feature_dim()\n",
    "    target_nodes= list(feature_dim.keys())\n",
    "\n",
    "    y_hat_dict= {}\n",
    "    y_true_dict= {}\n",
    "    \n",
    "    for _trf_str in ['trf', 'no_trf']:    \n",
    "        for _T in T_lst:\n",
    "            for k in target_nodes:\n",
    "                if (_trf_str !=  'no_trf') or (k != 'trf'):\n",
    "                    _df= pd.read_csv(os.path.join(results_path,f'y_hat_{_city}_{_T}_{k}_{_trf_str}.csv'), index_col=0)\n",
    "                    y_hat_dict['_'.join([str(_T),k,_trf_str])]= _df\n",
    "                \n",
    "                    _df= pd.read_csv(os.path.join(results_path,f'y_true_{_city}_{_T}_{k}_{_trf_str}.csv'), index_col=0)\n",
    "                    y_true_dict['_'.join([str(_T),k,_trf_str])]= _df\n",
    "\n",
    "\n",
    "    metrics_by_sensors= []\n",
    "    metrics_by_pollutants= []\n",
    "    for _trf_str in ['trf', 'no_trf']:    \n",
    "        for _T in T_lst:\n",
    "            for k in target_nodes:\n",
    "                if k != 'trf':\n",
    "                    y_true_df= y_true_dict['_'.join([str(_T),k,_trf_str])]\n",
    "                    y_hat_df= y_hat_dict['_'.join([str(_T),k,_trf_str])]\n",
    "                \n",
    "                    #Metris by station\n",
    "                    for i in range(y_true_df.shape[0]):\n",
    "                        mae, mse, rmse, cvrmse, mape= compute_metrics(y_true_df.iloc[i], y_hat_df.iloc[i])\n",
    "                        #print(y_true_df, y_hat_df, mae, mse, rmse, cvrmse, mape)\n",
    "                        metrics_by_sensors.append((_T, _trf_str, k, i, mae, mse, rmse, cvrmse, mape))\n",
    "                \n",
    "                    for c in y_true_df.columns:\n",
    "                        c_hat= y_hat_df[c].T\n",
    "                        c_true= y_true_df[c].T\n",
    "                        mae, mse, rmse, cvrmse, mape= compute_metrics(c_true, c_hat)\n",
    "                        metrics_by_pollutants.append((_T, _trf_str, k, c, mae, mse, rmse, cvrmse, mape))\n",
    "    \n",
    "    \n",
    "    metrics_by_sensors_df = pd.DataFrame.from_records(metrics_by_sensors, columns='T traffic sensor t MAE MSE RMSE CVRMSE MAPE'.split())\n",
    "    metrics_by_pollutants_df = pd.DataFrame.from_records(metrics_by_pollutants, columns='T traffic sensor pollutant MAE MSE RMSE CVRMSE MAPE'.split())\n",
    "    \n",
    "    metrics_by_sensors_df.to_csv(os.path.join(results_path,f'metrics_by_sensor_{_city}.csv'))\n",
    "    metrics_by_pollutants_df.to_csv(os.path.join(results_path,f'metrics_by_pollutant_{_city}.csv'))\n",
    "\n",
    "    print(\"*\"*8)\n",
    "    print(\"METRICS BY POLLUTANT\")\n",
    "    for t in T_lst:\n",
    "        print(\"*\"*4)\n",
    "        print(f\"{_city} - {t}h time horizon\")\n",
    "        metric_agg_mean_df= metrics_by_pollutants_df[metrics_by_pollutants_df['T']==t].drop(columns='sensor').groupby('pollutant T traffic'.split()).mean()\n",
    "        print(metric_agg_mean_df)\n",
    "\n",
    "    print(\"*\"*8)\n",
    "    print(\"METRICS BY SENSORS\")\n",
    "    for t in T_lst:\n",
    "        print(f\"{_city} - {t}h time horizon\")\n",
    "        metric_agg_mean_df= metrics_by_sensors_df[metrics_by_sensors_df['T']==t].groupby('sensor T traffic'.split()).mean()\n",
    "        print(metric_agg_mean_df)  \n",
    "        print(\"*\"*4)  \n",
    "\n",
    "    print(\"*\"*8)\n",
    "    print(\"FORECASTED VS REAL PLOTS\")\n",
    "\n",
    "    T_to_plot= '24'\n",
    "    if _city== 'bilbao':\n",
    "        T_to_plot= '12'\n",
    "    y_true_lst={}\n",
    "    y_hat_lst={}\n",
    "    for k,df in y_true_dict.items():\n",
    "        T_k= k.split('_')[0]\n",
    "        trf_k= k.split('_')[2]\n",
    "        s_k = k.split('_')[1]\n",
    "        if (T_to_plot == T_k) and (trf_k== 'trf') and (s_k != 'trf'): # We plot pollution sensors including traffic as input\n",
    "            y_hat_df= y_hat_dict[k]\n",
    "            for c in df.columns:\n",
    "                df_lst= y_true_lst.get(c,[])\n",
    "                df_lst.append(df[c].to_frame().reset_index())\n",
    "                y_true_lst[c]= df_lst\n",
    "    \n",
    "                df_lst= y_hat_lst.get(c,[])\n",
    "                df_lst.append(y_hat_df[c].to_frame().reset_index())\n",
    "                y_hat_lst[c]= df_lst\n",
    "    \n",
    "    for k, lst in y_true_lst.items():\n",
    "        \n",
    "        df= pd.concat(lst, axis=0)\n",
    "        df= df.groupby('index').mean()\n",
    "        df= df.rename(columns={k:f'{k}_true'})\n",
    "    \n",
    "        lst2= y_hat_lst[k]\n",
    "        y_hat_df= pd.concat(lst2, axis=0)\n",
    "        y_hat_df= y_hat_df.groupby('index').mean()\n",
    "        y_hat_df= y_hat_df.rename(columns={k:f'{k}_forecasted'})\n",
    "        \n",
    "        ax=df.plot(grid=True, figsize=(15,5));\n",
    "        y_hat_df.plot(ax=ax, grid=True, xlabel='Snapshot', title=f'{_city} {k}');\n",
    "        \n",
    "        plt.savefig(os.path.join(os.path.join('figs', f'true_vs_forecast_{k}_{T_to_plot}_{_city}.png')), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ae4c2-3386-4b7a-8ca2-6608018550a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"That's all folks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15595f5-cc4f-48fd-bd03-f8b84ccc2b0a",
   "metadata": {},
   "source": [
    "# Test code (do not run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f17d6c-6581-4f0d-8423-e27339cdb27d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "T_lst= [12,24] #target time horizons to analyze\n",
    "_city= 'madrid'\n",
    "_include_trf= True # include or not traffic data as input\n",
    "\n",
    "results_path='results'\n",
    "\n",
    "loader= AirpollutionDatasetLoader(_city, _include_trf)\n",
    "dataset=loader.get_dataset(T=T_lst[0])\n",
    "\n",
    "feature_dim= loader.get_feature_dim()\n",
    "feature_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355a8c3-4375-40bc-9dfd-ec59306b0f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_nodes= list(feature_dim.keys())\n",
    "target_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02a6c0-c0a8-4827-a6b6-79d742aebe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_dict= {}\n",
    "y_true_dict= {}\n",
    "\n",
    "for _trf_str in ['trf', 'no_trf']:    \n",
    "    for _T in T_lst:\n",
    "        for k in target_nodes:\n",
    "            if (_trf_str !=  'no_trf') or (k != 'trf'):\n",
    "                _df= pd.read_csv(os.path.join(results_path,f'y_hat_{_city}_{_T}_{k}_{_trf_str}.csv'), index_col=0)\n",
    "                y_hat_dict['_'.join([str(_T),k,_trf_str])]= _df\n",
    "            \n",
    "                _df= pd.read_csv(os.path.join(results_path,f'y_true_{_city}_{_T}_{k}_{_trf_str}.csv'), index_col=0)\n",
    "                y_true_dict['_'.join([str(_T),k,_trf_str])]= _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe78f79-7ce9-41c2-99eb-f3aaf0094896",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93825b35-5b88-4862-b242-67a6606922d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_by_sensors= []\n",
    "metrics_by_pollutants= []\n",
    "for _trf_str in ['trf', 'no_trf']:    \n",
    "    for _T in T_lst:\n",
    "        for k in target_nodes:\n",
    "            if k != 'trf':\n",
    "                y_true_df= y_true_dict['_'.join([str(_T),k,_trf_str])]\n",
    "                y_hat_df= y_hat_dict['_'.join([str(_T),k,_trf_str])]\n",
    "            \n",
    "                #Metris by station\n",
    "                for i in range(y_true_df.shape[0]):\n",
    "                    mae, mse, rmse, cvrmse, mape= compute_metrics(y_true_df.iloc[i], y_hat_df.iloc[i])\n",
    "                    #print(y_true_df, y_hat_df, mae, mse, rmse, cvrmse, mape)\n",
    "                    metrics_by_sensors.append((_T, _trf_str, k, i, mae, mse, rmse, cvrmse, mape))\n",
    "            \n",
    "                for c in y_true_df.columns:\n",
    "                    c_hat= y_hat_df[c].T\n",
    "                    c_true= y_true_df[c].T\n",
    "                    mae, mse, rmse, cvrmse, mape= compute_metrics(c_true, c_hat)\n",
    "                    metrics_by_pollutants.append((_T, _trf_str, k, c, mae, mse, rmse, cvrmse, mape))\n",
    "\n",
    "\n",
    "metrics_by_sensors_df = pd.DataFrame.from_records(metrics_by_sensors, columns='T traffic sensor t MAE MSE RMSE CVRMSE MAPE'.split())\n",
    "metrics_by_pollutants_df = pd.DataFrame.from_records(metrics_by_pollutants, columns='T traffic sensor pollutant MAE MSE RMSE CVRMSE MAPE'.split())\n",
    "\n",
    "metrics_by_sensors_df.to_csv(os.path.join(results_path,f'metrics_by_sensor_{_city}.csv'))\n",
    "metrics_by_pollutants_df.to_csv(os.path.join(results_path,f'metrics_by_pollutant_{_city}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42154c0-c79b-4601-8da6-610ee8a5d411",
   "metadata": {},
   "source": [
    "### Metrics by sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad6984-44e5-46c2-b4bc-9273106d6d8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_by_sensors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4120138-fc98-4068-8923-d4c8650f2e73",
   "metadata": {},
   "source": [
    "12 hours horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45236e95-c880-4948-98c2-b4b45a2ed886",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_agg_mean_df= metrics_by_sensors_df[metrics_by_sensors_df['T']==12].groupby('sensor T traffic'.split()).mean()\n",
    "metric_agg_mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948d284-2185-48f3-b966-1b4efeab8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_agg_mean_df= metrics_by_sensors_df[metrics_by_sensors_df['T']==12].groupby('sensor T traffic t'.split()).mean().reset_index()\n",
    "metric_agg_mean_df[metric_agg_mean_df['t']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a814a-3eef-4a7c-89a1-4b658d0dcf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_agg_mean_df[metric_agg_mean_df['t']==6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132511a0-faf5-4baa-8c55-e56d033c1aa2",
   "metadata": {},
   "source": [
    "24 hours horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71406bf8-4be6-4128-8031-d8c7e0e3989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_agg_mean_df= metrics_by_sensors_df[metrics_by_sensors_df['T']==24].groupby('sensor T traffic'.split()).mean()\n",
    "metric_agg_mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771db045-2adc-4ae7-898b-c17750ef2e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_agg_mean_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff50ac5-4531-49c7-9633-a36f0f6b06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_agg_mean_df= metric_agg_mean_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41a8b8-5b67-4768-ac7e-c40371cd1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_trf= metric_agg_mean_df[metric_agg_mean_df['traffic']=='trf']['RMSE']\n",
    "metric_no_trf= metric_agg_mean_df[metric_agg_mean_df['traffic']=='no_trf']['RMSE']\n",
    "metric_trf, metric_no_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c3f69c-1660-43d7-9b8d-da83a6b124c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(metric_trf, metric_no_trf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d5d16d-c6cf-4262-99c6-6291e161d500",
   "metadata": {},
   "source": [
    "## Metrics by pollutants\n",
    "\n",
    "12 hours horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ca6a0-43a1-4586-a3dc-3fd95fe9bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_agg_mean_df= metrics_by_pollutants_df[metrics_by_pollutants_df['T']==12].drop(columns='sensor').groupby('pollutant T traffic'.split()).mean()\n",
    "metric_agg_mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b848057-6297-4569-9a56-fe72890d836a",
   "metadata": {},
   "source": [
    "24 hours horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d3aa2-952c-464f-b2bb-5a4308e3582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_agg_mean_df= metrics_by_pollutants_df[metrics_by_pollutants_df['T']==24].drop(columns='sensor').groupby('pollutant T traffic'.split()).mean()\n",
    "metric_agg_mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52950892-d178-46b0-a414-a34a362514c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_by_pollutants_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4c810-8109-4bc3-9483-eefccfac72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in metrics_by_pollutants_df['pollutant'].unique():\n",
    "    for m in 'MAE RMSE CVRMSE MAPE'.split():\n",
    "        metric_trf= metrics_by_pollutants_df[(metrics_by_pollutants_df['traffic']=='trf') & \n",
    "        (metrics_by_pollutants_df['pollutant']==c)][m]\n",
    "        \n",
    "        metric_no_trf= metrics_by_pollutants_df[(metrics_by_pollutants_df['traffic']=='no_trf') & \n",
    "        (metrics_by_pollutants_df['pollutant']==c)][m]\n",
    "        print(c,m)\n",
    "        print(ttest_ind(metric_trf, metric_no_trf, equal_var=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fe0134-12ce-4f9e-8c23-2324bd86f254",
   "metadata": {},
   "source": [
    "## Plot forecasted vs real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788b290f-c1e1-4988-8c71-ae6041dca4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_to_plot='24'\n",
    "y_true_lst={}\n",
    "y_hat_lst={}\n",
    "for k,df in y_true_dict.items():\n",
    "    y_hat_df= y_hat_dict[k]\n",
    "    if (T_to_plot in k) and ('no_trf' in k):\n",
    "        for c in df.columns:\n",
    "            df_lst= y_true_lst.get(c,[])\n",
    "            df_lst.append(df[c].to_frame().reset_index())\n",
    "            y_true_lst[c]= df_lst\n",
    "\n",
    "            df_lst= y_hat_lst.get(c,[])\n",
    "            df_lst.append(y_hat_df[c].to_frame().reset_index())\n",
    "            y_hat_lst[c]= df_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9380c-4901-46e4-b081-1475f612d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_trf_str= 'trf'\n",
    "if not _include_trf:\n",
    "    _trf_str='no_trf'\n",
    "\n",
    "for k, lst in y_true_lst.items():\n",
    "    \n",
    "    df= pd.concat(lst, axis=0)\n",
    "    df= df.groupby('index').mean()\n",
    "    df= df.rename(columns={k:f'{k}_true'})\n",
    "\n",
    "    lst2= y_hat_lst[k]\n",
    "    y_hat_df= pd.concat(lst2, axis=0)\n",
    "    y_hat_df= y_hat_df.groupby('index').mean()\n",
    "    y_hat_df= y_hat_df.rename(columns={k:f'{k}_forecasted'})\n",
    "    \n",
    "    ax=df.plot(grid=True, figsize=(15,5));\n",
    "    y_hat_df.plot(ax=ax, grid=True, xlabel='Snapshot');\n",
    "    \n",
    "\n",
    "    plt.savefig(os.path.join(os.path.join('figs', f'true_vs_forecast_{k}_{T_to_plot}_{_city}_{_trf_str}.png')), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
