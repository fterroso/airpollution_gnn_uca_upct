{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "101cf426-a84f-420d-9953-1d86e0b6b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "from torch.nn import ModuleList, ModuleDict\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric_temporal.nn.hetero import HeteroGCLSTM\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "from airpollution_trf_graph_loader import AirpollutionDatasetLoader\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "604e8314-2659-4852-a88e-aa9c2cfca010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers= 2\n",
    "device_ =torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ff723d-b89c-4d54-8086-7168591e5e31",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f831f79-f4ce-4909-8dc4-b742ccdb2b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trf': 4, 'ap0': 2, 'ap1': 5, 'ap2': 2, 'ap3': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader= AirpollutionDatasetLoader('madrid')\n",
    "dataset=loader.get_dataset(T=12)\n",
    "feature_dim= loader.get_feature_dim()\n",
    "feature_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2d678-686a-4623-8d7a-f213541b3b07",
   "metadata": {},
   "source": [
    "## Define GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e804d4-079e-4896-890c-ade41b3af7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels_dict, out_channels, metadata, nlayers=2):\n",
    "        super(HeteroGNN, self).__init__()      \n",
    "        self.linears= ModuleDict({v:torch.nn.Linear(128,i) for v,i in in_channels_dict.items()})\n",
    "        self.n_conv_layers=nlayers\n",
    "\n",
    "        self.convs=ModuleList()\n",
    "        self.convs.append(HeteroGCLSTM(in_channels_dict=in_channels_dict, out_channels=128, metadata=metadata))\n",
    "        \n",
    "        new_in_channel_dict={v:128 for v,i in in_channels_dict.items()}\n",
    "        for l in range(0,self.n_conv_layers-1):\n",
    "            self.convs.append(HeteroGCLSTM(in_channels_dict=new_in_channel_dict, out_channels=128, metadata=metadata))\n",
    "        \n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, h_dict_lst, c_dict_lst):\n",
    "        new_h_lst=[]\n",
    "        new_c_lst=[]\n",
    "        x= x_dict\n",
    "        for i in range(0,self.n_conv_layers):\n",
    "            h, c= self.convs[i](x, edge_index_dict)\n",
    "            x = {key: val.relu() for key, val in h.items()}\n",
    "            new_h_lst.append(x)\n",
    "            new_c_lst.append(c)\n",
    "        \n",
    "        h= {v: self.linears[v](emb_) for v,emb_ in x.items()}\n",
    "        new_h_lst.append(h)\n",
    "        return new_h_lst, new_c_lst\n",
    "\n",
    "embedding_dim=1\n",
    "model = HeteroGNN(in_channels_dict=feature_dim, out_channels= embedding_dim, metadata=dataset[0].metadata(), nlayers=n_layers)\n",
    "model = model.to(device_)\n",
    "    \n",
    "train_dataset, test_dataset = temporal_signal_split(dataset,  train_ratio=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de5b026-c77a-407a-9652-bee67fd85765",
   "metadata": {},
   "source": [
    "## Train GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27758f2c-ef31-4486-83e2-0852c682494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training parameters\n",
    "n_epochs=600\n",
    "batch_size= 24 * 1 #hours (3-day batch)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def calculate_loss(y_hat_dict, y_dict):\n",
    "    loss_= 0\n",
    "\n",
    "    for p in y_hat_dict.keys():\n",
    "        if p != 'trf':\n",
    "            y_hat= y_hat_dict[p]\n",
    "            y_hat= torch.nan_to_num(y_hat)\n",
    "            particle_loss = torch.mean((y_hat-y_dict[p])**2) #MSE\n",
    "            loss_ += particle_loss\n",
    "    return loss_\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "early_stopper = EarlyStopper(patience=5, min_delta=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(n_epochs), desc='Training epochs...'):\n",
    "    \n",
    "    batch_loss = 0\n",
    "    counter=1    \n",
    "    \n",
    "    train_epoch_cost =0\n",
    "    eval_epoch_cost= 0\n",
    "    h_lst=[None for i in range(0,n_layers)]\n",
    "    c_lst=[None for i in range(0,n_layers)]\n",
    "        \n",
    "    #train\n",
    "    for time, train_snapshot in tqdm(enumerate(train_dataset), desc='Train snapshots...', leave=False):\n",
    "\n",
    "        h_lst, c_lst = model(train_snapshot.x_dict, train_snapshot.edge_index_dict, h_lst, c_lst)\n",
    "\n",
    "        h_dict= h_lst[-1]\n",
    "\n",
    "        snap_train_loss= calculate_loss(h_dict, train_snapshot.y_dict)\n",
    "        \n",
    "        train_epoch_cost = train_epoch_cost + snap_train_loss  \n",
    "        batch_loss = batch_loss + snap_train_loss\n",
    "        \n",
    "        if counter == batch_size:\n",
    "            batch_loss = batch_loss / batch_size\n",
    "            batch_loss.backward(retain_graph=True)\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            counter=1\n",
    "            batch_loss= 0\n",
    "            \n",
    "            h_lst=[None for i in range(0,n_layers)]\n",
    "            c_lst=[None for i in range(0,n_layers)]\n",
    "            \n",
    "        else:\n",
    "            counter += 1\n",
    "    \n",
    "    \n",
    "    train_epoch_cost = train_epoch_cost / (time+1)\n",
    "    \n",
    "    \n",
    "    # validation \n",
    "    with torch.no_grad(): \n",
    "        eval_h_lst=[None for i in range(0,n_layers)]\n",
    "        eval_c_lst=[None for i in range(0,n_layers)]\n",
    "        for time, test_snapshot in tqdm(enumerate(test_dataset), desc='Eval snapshots...', leave=False):\n",
    "            eval_h_lst, eval_c_lst = model(test_snapshot.x_dict, test_snapshot.edge_index_dict, eval_h_lst, eval_c_lst) \n",
    "            snap_eval_loss= calculate_loss(eval_h_lst[-1], test_snapshot.y_dict)\n",
    "        \n",
    "            eval_epoch_cost = eval_epoch_cost + snap_eval_loss\n",
    "    eval_epoch_cost = eval_epoch_cost / (time+1)\n",
    "   \n",
    "    if early_stopper.early_stop(eval_epoch_cost):             \n",
    "        print(f'EARLY STOP  AT epoch {epoch} - MSE (train): {train_epoch_cost}  - MSE (test): {eval_epoch_cost}')\n",
    "        break\n",
    "    print(f'Epoch {epoch} - MSE (train): {train_epoch_cost}  - MSE (test): {eval_epoch_cost}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
