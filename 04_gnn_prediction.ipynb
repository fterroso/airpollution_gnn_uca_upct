{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "101cf426-a84f-420d-9953-1d86e0b6b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "from torch.nn import ModuleList, ModuleDict\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric_temporal.nn.hetero import HeteroGCLSTM\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "from airpollution_trf_graph_loader import AirpollutionDatasetLoader\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "604e8314-2659-4852-a88e-aa9c2cfca010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers= 2\n",
    "device_ =torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ff723d-b89c-4d54-8086-7168591e5e31",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f831f79-f4ce-4909-8dc4-b742ccdb2b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trf': 4, 'ap0': 2, 'ap1': 5, 'ap2': 2, 'ap3': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader= AirpollutionDatasetLoader('madrid')\n",
    "dataset=loader.get_dataset(T=6)\n",
    "feature_dim= loader.get_feature_dim()\n",
    "feature_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2d678-686a-4623-8d7a-f213541b3b07",
   "metadata": {},
   "source": [
    "## Define GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e804d4-079e-4896-890c-ade41b3af7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels_dict, out_channels, metadata, nlayers=2):\n",
    "        super(HeteroGNN, self).__init__()      \n",
    "        self.linears= ModuleDict({v:torch.nn.Linear(128,i) for v,i in in_channels_dict.items()})\n",
    "        self.n_conv_layers=nlayers\n",
    "\n",
    "        self.convs=ModuleList()\n",
    "        self.convs.append(HeteroGCLSTM(in_channels_dict=in_channels_dict, out_channels=128, metadata=metadata))\n",
    "        \n",
    "        new_in_channel_dict={v:128 for v,i in in_channels_dict.items()}\n",
    "        for l in range(0,self.n_conv_layers-1):\n",
    "            self.convs.append(HeteroGCLSTM(in_channels_dict=new_in_channel_dict, out_channels=128, metadata=metadata))\n",
    "        \n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, h_dict_lst, c_dict_lst):\n",
    "        new_h_lst=[]\n",
    "        new_c_lst=[]\n",
    "        x= x_dict\n",
    "        for i in range(0,self.n_conv_layers):\n",
    "            h, c= self.convs[i](x, edge_index_dict)\n",
    "            x = {key: val.relu() for key, val in h.items()}\n",
    "            new_h_lst.append(x)\n",
    "            new_c_lst.append(c)\n",
    "        \n",
    "        h= {v: self.linears[v](emb_) for v,emb_ in x.items()}\n",
    "        new_h_lst.append(h)\n",
    "        return new_h_lst, new_c_lst\n",
    "\n",
    "embedding_dim=1\n",
    "model = HeteroGNN(in_channels_dict=feature_dim, out_channels= embedding_dim, metadata=dataset[0].metadata(), nlayers=n_layers)\n",
    "model = model.to(device_)\n",
    "    \n",
    "train_dataset, test_dataset = temporal_signal_split(dataset,  train_ratio=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de5b026-c77a-407a-9652-bee67fd85765",
   "metadata": {},
   "source": [
    "## Train GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27758f2c-ef31-4486-83e2-0852c682494b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198b0a5f5787419281e3e2042bc580c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs...:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d767ad3f19ab4bd9877af8b1ad2e01d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train snapshots...: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#train\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m time, train_snapshot \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_dataset), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain snapshots...\u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 51\u001b[0m     h_lst, c_lst \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_snapshot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_snapshot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_lst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_lst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     h_dict\u001b[38;5;241m=\u001b[39m h_lst[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     55\u001b[0m     snap_train_loss\u001b[38;5;241m=\u001b[39m calculate_loss(h_dict, train_snapshot\u001b[38;5;241m.\u001b[39my_dict)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\airpollution_gnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\airpollution_gnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m, in \u001b[0;36mHeteroGNN.forward\u001b[1;34m(self, x_dict, edge_index_dict, h_dict_lst, c_dict_lst)\u001b[0m\n\u001b[0;32m     18\u001b[0m x\u001b[38;5;241m=\u001b[39m x_dict\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_conv_layers):\n\u001b[1;32m---> 20\u001b[0m     h, c\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m#print(i)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m#print(\"*\"*8)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m#print(h['ap1'].shape)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     x \u001b[38;5;241m=\u001b[39m {key: val\u001b[38;5;241m.\u001b[39mrelu() \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m h\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\airpollution_gnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\airpollution_gnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\airpollution_gnn\\lib\\site-packages\\torch_geometric_temporal\\nn\\hetero\\heterogclstm.py:180\u001b[0m, in \u001b[0;36mHeteroGCLSTM.forward\u001b[1;34m(self, x_dict, edge_index_dict, h_dict, c_dict)\u001b[0m\n\u001b[0;32m    178\u001b[0m i_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_input_gate(x_dict, edge_index_dict, h_dict, c_dict)\n\u001b[0;32m    179\u001b[0m f_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_forget_gate(x_dict, edge_index_dict, h_dict, c_dict)\n\u001b[1;32m--> 180\u001b[0m c_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_cell_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m o_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_output_gate(x_dict, edge_index_dict, h_dict, c_dict)\n\u001b[0;32m    182\u001b[0m h_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_hidden_state(o_dict, c_dict)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\airpollution_gnn\\lib\\site-packages\\torch_geometric_temporal\\nn\\hetero\\heterogclstm.py:128\u001b[0m, in \u001b[0;36mHeteroGCLSTM._calculate_cell_state\u001b[1;34m(self, x_dict, edge_index_dict, h_dict, c_dict, i_dict, f_dict)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calculate_cell_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_dict, edge_index_dict, h_dict, c_dict, i_dict, f_dict):\n\u001b[0;32m    127\u001b[0m     t_dict \u001b[38;5;241m=\u001b[39m {node_type: torch\u001b[38;5;241m.\u001b[39mmatmul(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_c[node_type]) \u001b[38;5;28;01mfor\u001b[39;00m node_type, X \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m--> 128\u001b[0m     conv_c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m     t_dict \u001b[38;5;241m=\u001b[39m {node_type: T \u001b[38;5;241m+\u001b[39m conv_c[node_type] \u001b[38;5;28;01mfor\u001b[39;00m node_type, T \u001b[38;5;129;01min\u001b[39;00m t_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    130\u001b[0m     t_dict \u001b[38;5;241m=\u001b[39m {node_type: T \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_c[node_type] \u001b[38;5;28;01mfor\u001b[39;00m node_type, T \u001b[38;5;129;01min\u001b[39;00m t_dict\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\airpollution_gnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\airpollution_gnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\airpollution_gnn\\lib\\site-packages\\torch_geometric\\nn\\conv\\hetero_conv.py:130\u001b[0m, in \u001b[0;36mHeteroConv.forward\u001b[1;34m(self, x_dict, edge_index_dict, *args_dict, **kwargs_dict)\u001b[0m\n\u001b[0;32m    128\u001b[0m         out \u001b[38;5;241m=\u001b[39m conv(x_dict[src], edge_index, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m         out \u001b[38;5;241m=\u001b[39m conv((x_dict[src], x_dict[dst]), edge_index, \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    131\u001b[0m                    \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    133\u001b[0m     out_dict[dst]\u001b[38;5;241m.\u001b[39mappend(out)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m out_dict\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\airpollution_gnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\airpollution_gnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\airpollution_gnn\\lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:138\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[1;34m(self, x, edge_index, size)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_weight \u001b[38;5;129;01mand\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_r(x_r)\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize:\n\u001b[0;32m    139\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(out, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training parameters\n",
    "n_epochs=600\n",
    "batch_size= 24 * 1 #hours (3-day batch)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def calculate_loss(y_hat_dict, y_dict):\n",
    "    loss_= 0\n",
    "\n",
    "    for p in y_hat_dict.keys():\n",
    "        if p != 'trf':\n",
    "            y_hat= y_hat_dict[p]\n",
    "            y_hat= torch.nan_to_num(y_hat)\n",
    "            particle_loss = torch.mean((y_hat-y_dict[p])**2) #MSE\n",
    "            loss_ += particle_loss\n",
    "    return loss_\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "early_stopper = EarlyStopper(patience=5, min_delta=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(n_epochs), desc='Training epochs...'):\n",
    "    \n",
    "    batch_loss = 0\n",
    "    counter=1    \n",
    "    \n",
    "    train_epoch_cost =0\n",
    "    eval_epoch_cost= 0\n",
    "    h_lst=[None for i in range(0,n_layers)]\n",
    "    c_lst=[None for i in range(0,n_layers)]\n",
    "        \n",
    "    #train\n",
    "    for time, train_snapshot in tqdm(enumerate(train_dataset), desc='Train snapshots...', leave=False):\n",
    "\n",
    "        h_lst, c_lst = model(train_snapshot.x_dict, train_snapshot.edge_index_dict, h_lst, c_lst)\n",
    "\n",
    "        h_dict= h_lst[-1]\n",
    "\n",
    "        snap_train_loss= calculate_loss(h_dict, train_snapshot.y_dict)\n",
    "        \n",
    "        train_epoch_cost = train_epoch_cost + snap_train_loss  \n",
    "        batch_loss = batch_loss + snap_train_loss\n",
    "        \n",
    "        if counter == batch_size:\n",
    "            batch_loss = batch_loss / batch_size\n",
    "            batch_loss.backward(retain_graph=True)\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            counter=1\n",
    "            batch_loss= 0\n",
    "            \n",
    "            h_lst=[None for i in range(0,n_layers)]\n",
    "            c_lst=[None for i in range(0,n_layers)]\n",
    "            \n",
    "        else:\n",
    "            counter += 1\n",
    "    \n",
    "    \n",
    "    train_epoch_cost = train_epoch_cost / (time+1)\n",
    "    \n",
    "    \n",
    "    # validation \n",
    "    with torch.no_grad(): \n",
    "        eval_h_lst=[None for i in range(0,n_layers)]\n",
    "        eval_c_lst=[None for i in range(0,n_layers)]\n",
    "        for time, test_snapshot in tqdm(enumerate(test_dataset), desc='Eval snapshots...', leave=False):\n",
    "            eval_h_lst, eval_c_lst = model(test_snapshot.x_dict, test_snapshot.edge_index_dict, eval_h_lst, eval_c_lst) \n",
    "            snap_eval_loss= calculate_loss(eval_h_lst[-1], test_snapshot, target_particles)\n",
    "        \n",
    "            eval_epoch_cost = eval_epoch_cost + snap_eval_loss\n",
    "    eval_epoch_cost = eval_epoch_cost / (time+1)\n",
    "   \n",
    "    if early_stopper.early_stop(eval_epoch_cost):             \n",
    "        print(f'EARLY STOP  AT epoch {epoch} - MSE (train): {train_epoch_cost}  - MSE (test): {eval_epoch_cost}')\n",
    "        break\n",
    "    print(f'Epoch {epoch} - MSE (train): {train_epoch_cost}  - MSE (test): {eval_epoch_cost}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
